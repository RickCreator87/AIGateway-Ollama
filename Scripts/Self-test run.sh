#!/bin/bash
set -euo pipefail

echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "ğŸ” Ollama Stack Selfâ€‘Test"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

# 1. Environment diagnostics
echo "ğŸ“¦ Step 1: Environment check"
echo "â†’ Running on: $(uname -a)"
echo "â†’ Current directory: $(pwd)"
echo "â†’ Files present:"
ls -al
echo ""

# 2. Check if Ollama is installed
echo "ğŸ“¦ Step 2: Checking for Ollama binary"
if ! command -v ollama >/dev/null 2>&1; then
  echo "âŒ Ollama not found in PATH"
  echo "This is expected on GitHub Actions unless you install it."
  exit 1   # Signal test failure; CI can be configured to allow this
else
  echo "âœ… Ollama binary found"
fi
echo ""

# 3. Try listing models (safe even if none exist)
echo "ğŸ“¦ Step 3: Listing available models"
if ollama list; then
  echo "âœ… Model list retrieved"
else
  echo "âš ï¸ Could not list models (may be expected)"
fi
echo ""

# 4. Optional: Run a lightweight test prompt
echo "ğŸ“¦ Step 4: Running lightweight test prompt"
if ollama run llama3 "Hello from CI" >/dev/null 2>&1; then
  echo "âœ… Model responded successfully"
else
  echo "âš ï¸ Model test skipped or failed (may be expected)"
fi
echo ""

echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "ğŸ‰ Selfâ€‘test completed"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
